---
title: "Sentiment Analysis with Pre-trained Language Models"
excerpt: "Fine-tuning pre-trained language model for sentiment analysis on SST-2 dataset."
collection: portfolio
---

<p><strong>Overview:</strong> Fine-tuned a language model for sentiment analysis on the SST-2 dataset, identifying movie review sentiments as negative or positive.</p>
<p><strong>Approach:</strong> Adapted Hugging Face's EleutherAI/pythia-70m model for sequence classification and trained it using specific parameters over 3 epochs.</p>
<p><strong>QLoRA and Its Inapplicability:</strong> Explored but did not integrate QLoRA due to incompatibility with the GPT-based pythia-70m model.</p>
<p><strong>Results:</strong> Achieved 81.65% accuracy on SST-2 validation set, with additional metrics demonstrating effective model performance.</p>
<p><strong>Additional Insights:</strong> Investigated QLoRA's connection to SVD, reflected on parameter tuning challenges, and highlighted the superiority of GPUs over CPUs for training.</p>

---
